<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" class="logo" width="120"/>

# Universal AI Assistant Architecture Blueprint for 2025

This comprehensive research analysis synthesizes the latest standards, protocols, and best practices for creating fully portable, modular, and stateful LLM agents [^1_1][^1_2][^1_3]. The blueprint represents a paradigm shift toward universal interoperability and modularity in AI agent design [^1_4][^1_5][^1_6].

## Executive Summary

The Universal AI Assistant architecture represents the evolution of AI agent systems from rigid, framework-specific implementations to flexible, interoperable platforms [^1_4][^1_5][^1_7]. This blueprint establishes five core layers: the Knowledge Layer with modular RAG systems, the Core Agent Layer with universal manifests, the Protocol Layer enabling MCP and A2A communication, the Memory Layer with pluggable systems, and Framework Adapters ensuring portability [^1_8][^1_9][^1_10]. The architecture prioritizes stateful memory management, protocol-based interoperability, and framework-agnostic deployment capabilities [^1_10][^1_11][^1_12].

## The Post-Framework Era: From Linear Chains to Dynamic Graphs

The AI agent landscape has undergone a fundamental architectural transformation from the early linear chain approaches to sophisticated, stateful agentic graph systems [^1_4][^1_5][^1_13]. Early LangChain implementations relied on simple sequential processing with stateless operations, limiting their ability to handle complex, multi-step reasoning tasks [^1_5][^1_13][^1_14]. This linear approach proved insufficient for production-grade applications requiring memory persistence, dynamic decision-making, and complex workflow orchestration [^1_5][^1_14][^1_15].

Modern frameworks like LangGraph have pioneered graph-based agent orchestration, enabling dynamic routing, conditional branching, and looping mechanisms [^1_5][^1_13][^1_16]. LangGraph's stateful architecture supports persistent memory management, human-in-the-loop interactions, and sophisticated state transitions that were impossible with linear chains [^1_5][^1_13][^1_17]. Haystack 2.0 has complemented this evolution with its modular pipeline architecture, emphasizing component reusability and production-ready deployment capabilities [^1_18][^1_19][^1_20].

AutoGen has introduced multi-agent conversation paradigms, where agents engage in structured dialogues to solve complex problems collaboratively [^1_15][^1_21][^1_22]. This approach moves beyond single-agent limitations by enabling specialized agents to contribute their expertise in coordinated workflows [^1_15][^1_21]. CrewAI has further refined this concept with role-based team structures, where agents assume specific responsibilities within hierarchical organizations [^1_23][^1_24][^1_25].

The emergence of MemEngine represents a critical advancement in memory-centric architectures, providing pluggable, serializable memory systems that can be transferred across different frameworks [^1_10][^1_11][^1_26]. This decoupled approach to memory management enables true portability and framework independence [^1_10][^1_12][^1_27].

## Interoperability Protocols: The USB-C for AI

### Model Context Protocol (MCP)

The Model Context Protocol functions as the foundational standard for connecting LLM applications with external tools and data sources [^1_1][^1_8][^1_9]. MCP operates on a JSON-RPC 2.0 transport layer, establishing stateful connections between hosts, clients, and servers [^1_8][^1_9][^1_28]. The protocol defines four core feature categories: Resources for contextual data access, Tools for LLM-executable functions, Prompts for templated workflows, and Sampling for server-initiated agentic behaviors [^1_8][^1_9].

MCP's security model emphasizes user consent and control, requiring explicit authorization for all data access and tool execution [^1_29][^1_30][^1_9]. The protocol implements comprehensive data privacy protections and tool safety measures, treating all external operations as potentially untrusted [^1_29][^1_30]. This security-first approach has led to enterprise adoption patterns where organizations can maintain strict control over AI system capabilities while enabling powerful integrations [^1_2][^1_31].

### Agent2Agent (A2A) Protocol

The Agent2Agent protocol addresses the critical need for standardized agent-to-agent communication across different platforms and frameworks [^1_3][^1_32][^1_33]. A2A utilizes HTTP, Server-Sent Events, and JSON-RPC for transport, supporting multi-modal communication including text, audio, and video streaming [^1_32][^1_33]. The protocol's Agent Card system enables dynamic capability discovery, allowing agents to advertise their skills and identify optimal collaboration partners [^1_32][^1_33].

A2A's task-oriented workflow follows a structured lifecycle from discovery through completion, supporting both immediate tasks and long-running research that may span hours or days [^1_32][^1_33]. The protocol's enterprise-grade security features include support for OpenAPI authentication schemes and comprehensive audit trails [^1_32][^1_33]. This design enables secure collaboration between agents across organizational boundaries while maintaining compliance requirements [^1_32][^1_6].

### Protocol Ecosystem Comparison

The interoperability protocol landscape demonstrates complementary rather than competing approaches [^1_3][^1_6]. MCP excels at LLM-tool integration scenarios, while A2A specializes in agent-agent collaboration workflows [^1_3][^1_32][^1_6]. Traditional protocols like OpenAPI continue to serve web service standardization needs, while JSON-RPC provides the foundational transport mechanisms [^1_3][^1_9].

## Universal Agent Manifest: Framework-Agnostic Schema

The Universal Agent Manifest represents a standardized approach to defining agent identity, capabilities, and configurations in a framework-agnostic manner [^1_34][^1_35][^1_36]. This YAML/JSON schema specification enables agents to be described independently of their underlying implementation frameworks, facilitating true portability [^1_37][^1_38][^1_39].

The manifest structure encompasses five critical sections: metadata for agent identification and versioning, specification details including identity, model configuration, and capabilities, memory system definitions supporting hybrid approaches, tool and protocol configurations for MCP and A2A integration, and deployment specifications with framework adapters [^1_34][^1_35][^1_39]. This comprehensive schema enables agents to be seamlessly migrated between different orchestration frameworks while preserving their core functionality and configuration [^1_37][^1_39].

The identity section defines the agent's role, persona, and capabilities, providing semantic information that other agents and systems can use for collaboration decisions [^1_36][^1_38][^1_39]. Model configuration supports multiple providers with fallback mechanisms, ensuring resilience across different LLM ecosystems [^1_34][^1_35]. The memory specification enables hybrid approaches combining working memory, long-term vector storage, and episodic structured memory [^1_34][^1_35].

## Modular Knowledge Core: Portable Knowledge Architectures

### Advanced RAG Systems

Modular RAG architectures have evolved beyond traditional retrieve-then-generate patterns to support complex, reconfigurable frameworks [^1_40][^1_41][^1_42]. These systems decompose RAG functionality into independent modules with specialized operators, enabling routing, scheduling, and fusion mechanisms [^1_40][^1_41]. The modular approach supports four primary patterns: linear for sequential processing, conditional for decision-based routing, branching for parallel execution, and looping for iterative refinement [^1_40][^1_41][^1_42].

The modularity enables dynamic component swapping during runtime, allowing systems to optimize retrieval strategies based on query characteristics and data types [^1_43][^1_44][^1_45]. This flexibility has proven particularly valuable in enterprise deployments where different document types and knowledge domains require specialized processing approaches [^1_46][^1_47][^1_45].

### Knowledge Packets (K-Packets)

Knowledge Packets represent a novel approach to self-describing, auditable knowledge representation [^1_48][^1_49]. These structured data objects embed comprehensive metadata, audit trails, and semantic relationships alongside the core knowledge content [^1_49]. K-Packets maintain provenance information, quality metrics, and lineage tracking throughout their lifecycle [^1_49].

The audit logic within K-Packets enables full traceability of knowledge transformation processes, supporting compliance requirements and knowledge quality assurance [^1_49]. This approach facilitates knowledge sharing across different agent systems while maintaining data integrity and verification capabilities [^1_49]. The semantic linking mechanisms enable K-Packets to form interconnected knowledge graphs that can be queried and reasoned over [^1_49].

### Vector Database Ecosystem

The vector database landscape offers diverse solutions optimized for different use cases and deployment scenarios [^1_50][^1_51][^1_52]. Chroma provides developer-friendly embedding storage with LangChain integration, making it ideal for rapid prototyping and small-scale deployments [^1_50][^1_51][^1_53]. FAISS delivers high-performance similarity search with GPU acceleration, suited for research and large-scale indexing applications [^1_50][^1_51][^1_53].

Weaviate combines vector search with built-in ML capabilities and GraphQL APIs, offering enterprise-ready features like multi-tenancy and cloud-native deployment [^1_50][^1_51][^1_52]. Qdrant provides advanced filtering capabilities with its Rust-based architecture, excelling in scenarios requiring complex payload-based queries [^1_50][^1_51][^1_52]. Milvus offers horizontal scaling and Kubernetes-native deployment, making it suitable for enterprise-scale vector search applications [^1_50][^1_51][^1_52].

## Pluggable Memory Systems: Decoupled Stateful Memory

Modern AI agents require sophisticated memory architectures that can persist state across sessions while remaining portable between different frameworks [^1_10][^1_11][^1_54]. MemEngine exemplifies this approach with its three-tier hierarchical architecture: memory functions for basic operations, memory operations for fundamental processes, and memory models for complete implementations [^1_10][^1_12][^1_26].

The modular design enables memory components to be independently scaled, configured, and transferred between agent systems [^1_10][^1_26]. MemEngine supports nine different memory models including full memory concatenation, semantic similarity-based retrieval, generative agent reflection, and hierarchical operating system-like structures [^1_12][^1_26]. This diversity allows agents to select optimal memory strategies based on their specific requirements and operational contexts [^1_12][^1_27].

![Memory System Architecture Comparison for AI Agents](https://pplx-res.cloudinary.com/image/upload/v1749917397/pplx_code_interpreter/fd62cf02_yu5q08.jpg)

Memory System Architecture Comparison for AI Agents

The decoupled architecture enables memory serialization and transfer, allowing agent memories to be packaged, moved, and restored across different execution environments [^1_10][^1_55][^1_54]. This capability is crucial for agent portability and enables scenarios like agent migration, backup and recovery, and distributed agent deployment [^1_10][^1_54].

## Universal AI Assistant Architecture

The Universal AI Assistant architecture integrates all components into a cohesive, five-layer system designed for maximum flexibility and interoperability [^1_8][^1_32][^1_10]. The architecture prioritizes modularity, enabling components to be independently updated, replaced, or scaled based on specific requirements [^1_18][^1_20].

![Universal AI Assistant Architecture Blueprint for 2025](https://pplx-res.cloudinary.com/image/upload/v1749917344/pplx_code_interpreter/fa7f17e6_a10ykx.jpg)

Universal AI Assistant Architecture Blueprint for 2025

The Core Agent Layer serves as the central orchestration point, managing the Universal Agent Manifest, coordinating state management, and abstracting model interactions [^1_34][^1_39]. The Protocol Layer enables seamless communication through MCP for tool integration and A2A for agent collaboration [^1_8][^1_32]. The Memory Layer provides persistent, transferable state management through pluggable memory systems [^1_10][^1_12].

Framework Adapters ensure compatibility with existing agent orchestration platforms, enabling the Universal AI Assistant to operate within LangGraph, Haystack, AutoGen, and CrewAI environments [^1_18][^1_15][^1_23]. The Knowledge Layer supports modular RAG systems and diverse vector database backends, providing flexible knowledge integration capabilities [^1_40][^1_50].

## Open-Source Framework Ecosystem

The open-source ecosystem provides the foundational components necessary for implementing the Universal AI Assistant architecture [^1_18][^1_20][^1_15]. LangGraph offers graph-based orchestration with stateful memory management, while Haystack 2.0 provides production-ready component pipelines [^1_18][^1_20]. AutoGen enables multi-agent conversations with human-in-the-loop capabilities, and CrewAI facilitates role-based team collaboration [^1_15][^1_23].

The ecosystem encompasses 19 major frameworks and protocols across five categories: AI Agent Frameworks, Memory Systems, Interoperability Protocols, Vector Databases, and foundational Research Papers [^1_50][^1_51]. This comprehensive landscape provides multiple implementation options for each architectural component, ensuring flexibility and avoiding vendor lock-in [^1_18][^1_50][^1_23].

## Conclusion

The Universal AI Assistant architecture blueprint represents a significant advancement toward truly portable, modular, and stateful AI agents [^1_4][^1_8][^1_10]. By standardizing protocols like MCP and A2A, implementing universal agent manifests, and enabling pluggable memory systems, this architecture addresses the critical challenges of framework lock-in and limited interoperability [^1_8][^1_32][^1_10]. The five-layer design provides clear separation of concerns while maintaining cohesive integration, enabling organizations to build sophisticated AI agents that can evolve with the rapidly advancing AI landscape [^1_18][^1_50][^1_23]. This blueprint serves as the foundation for the next generation of AI assistant systems, prioritizing flexibility, portability, and enterprise-grade capabilities [^1_8][^1_10][^1_18].

<div style="text-align: center">‚ÅÇ</div>

[^1_1]: https://arxiv.org/abs/2503.23278

[^1_2]: https://arxiv.org/abs/2504.08623

[^1_3]: https://www.semanticscholar.org/paper/18f349f0452eea2e9cce6b7d3424e0f9f7d9c5bc

[^1_4]: https://www.ijisrt.com/a-comprehensive-review-of-gen-ai-agents-applications-and-frameworks-in-finance-investments-and-risk-domains

[^1_5]: https://langchain-ai.github.io/langgraph/

[^1_6]: https://www.forrester.com/blogs/interoperability-is-key-to-unlocking-agentic-ais-future/

[^1_7]: https://virtust.com/stateful-ai-agents-stateless-llms-to-deliver-personalized-solutions/

[^1_8]: https://modelcontextprotocol.io/introduction

[^1_9]: https://modelcontextprotocol.io/specification/2025-03-26

[^1_10]: https://github.com/nuster1128/MemEngine

[^1_11]: https://arxiv.org/pdf/2505.02099.pdf

[^1_12]: https://www.themoonlight.io/en/review/memengine-a-unified-and-modular-library-for-developing-advanced-memory-of-llm-based-agents

[^1_13]: https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/

[^1_14]: https://python.langchain.com/api_reference/core/agents.html

[^1_15]: https://microsoft.github.io/autogen/0.2/docs/Use-Cases/agent_chat/

[^1_16]: https://www.linkedin.com/pulse/langgraph-architecture-built-langchain-srikanth-reddy-i8wac

[^1_17]: https://academy.langchain.com/courses/intro-to-langgraph

[^1_18]: https://haystack.deepset.ai/blog/haystack-2-release

[^1_19]: https://www.datacamp.com/tutorial/haystack-ai-tutorial

[^1_20]: https://github.com/deepset-ai/haystack

[^1_21]: https://www.projectpro.io/article/autogen/1139

[^1_22]: https://adasci.org/how-to-build-a-multi-agent-system-with-autogen/

[^1_23]: https://dev.to/lollypopdesign/choosing-the-right-ai-agent-frameworks-for-your-project-253a

[^1_24]: https://www.youtube.com/watch?v=pu2DG9FIab8

[^1_25]: https://www.aimletc.com/crew-ai-vs-langgraph-vs-autogen/

[^1_26]: https://www.linkedin.com/posts/ivan-martin-sanz-75584310b_llmagents-memoryops-mlops-activity-7327943201036648450-AsjD

[^1_27]: https://www.marktechpost.com/2025/05/20/researchers-from-renmin-university-and-huawei-propose-memengine-a-unified-modular-ai-library-for-customizing-memory-in-llm-based-agents/

[^1_28]: https://wandb.ai/onlineinference/mcp/reports/The-Model-Context-Protocol-MCP-by-Anthropic-Origins-functionality-and-impact--VmlldzoxMTY5NDI4MQ

[^1_29]: https://www.semanticscholar.org/paper/de816cdb08552df97907d827d734f2184b45ec38

[^1_30]: https://arxiv.org/abs/2504.03767

[^1_31]: https://www.anthropic.com/news/model-context-protocol

[^1_32]: https://www.solo.io/topics/ai/what-is-a2a

[^1_33]: https://a2aprotocol.ai

[^1_34]: https://learn.microsoft.com/en-us/microsoft-365-copilot/extensibility/declarative-agent-manifest-1.0

[^1_35]: https://learn.microsoft.com/en-us/microsoft-365-copilot/extensibility/declarative-agent-manifest-1.2

[^1_36]: https://docs.agntcy.org/pages/agws/manifest.html

[^1_37]: https://docs.dify.ai/en/plugins/schema-definition/manifest

[^1_38]: https://agent-network-protocol.com/specs/agent-description.html

[^1_39]: https://github.com/agile-lab-dev/Agent-Specification/blob/main/agent-specification.yaml

[^1_40]: https://arxiv.org/abs/2407.21059

[^1_41]: https://arxiv.org/html/2407.21059v1

[^1_42]: http://arxiv.org/pdf/2407.21059.pdf

[^1_43]: https://arxiv.org/abs/2504.18024

[^1_44]: https://nuclia.com/ai/what-is-modular-rag/

[^1_45]: https://aws.amazon.com/blogs/publicsector/use-modular-architecture-for-flexible-and-extensible-rag-based-generative-ai-solutions/

[^1_46]: https://www.mdpi.com/2076-3417/14/18/8259

[^1_47]: https://ijarsct.co.in/Paper18099.pdf

[^1_48]: https://podcasts.apple.com/us/podcast/understanding-knowledge-packets/id1497596897?i=1000464508217

[^1_49]: https://dl.acm.org/doi/pdf/10.1145/141356.141388

[^1_50]: https://www.shakudo.io/blog/top-9-vector-databases

[^1_51]: https://www.datacamp.com/blog/the-top-5-vector-databases

[^1_52]: https://www.cloudraft.io/blog/top-5-vector-databases

[^1_53]: https://www.gpu-mart.com/blog/top-5-open-source-vector-databases-2024/

[^1_54]: https://www.microsoft.com/en-us/research/publication/language-models-augmented-with-decoupled-memory/

[^1_55]: https://stackoverflow.com/questions/29026774/stateful-session-bean-passivation-and-serialization-ejb

[^1_56]: https://www.semanticscholar.org/paper/5ff0b29a8ef7e57ff430f123e9acbc290ad5ebd1

[^1_57]: https://www.semanticscholar.org/paper/90cfc4801ef90cdce68e28b8528991366781b7bd

[^1_58]: https://sol.sbc.org.br/index.php/sbsi_estendido/article/view/34585

[^1_59]: https://advanced.onlinelibrary.wiley.com/doi/10.1002/advs.202570136

[^1_60]: https://arxiv.org/abs/2503.11659

[^1_61]: https://www.sciltp.com/journals/matsus/2025/1/646

[^1_62]: https://www.ibm.com/think/topics/langgraph

[^1_63]: https://arxiv.org/html/2410.09824v2

[^1_64]: https://www.aimfluance.com/post/defining-the-post-ai-era-a-holistic-framework-for-societal-transformation

[^1_65]: https://github.com/statelyai/agent?tab=readme-ov-file

[^1_66]: https://www.ijfmr.com/research-paper.php?id=43583

[^1_67]: https://www.semanticscholar.org/paper/65e9d868acf9b571fab904cd4a97841b2661a84e

[^1_68]: https://arxiv.org/abs/2504.21030

[^1_69]: https://en.wikipedia.org/wiki/Model_Context_Protocol

[^1_70]: https://boringowl.io/blog/co-to-jest-mcp-model-context-protocol

[^1_71]: https://www.frontiersin.org/articles/10.3389/frvir.2025.1389318/full

[^1_72]: https://www.semanticscholar.org/paper/6f35e7cef1c5f4d63ca0c8084139d40a4f0ff1d4

[^1_73]: https://github.com/lando22/agents.json

[^1_74]: https://docs.yellow.ai/docs/platform_concepts/Getting%20Started/modify-bot-configuration

[^1_75]: https://www.tandfonline.com/doi/full/10.1080/19397038.2019.1634157

[^1_76]: https://jisem-journal.com/index.php/journal/article/view/11163

[^1_77]: https://www.semanticscholar.org/paper/5df048b4f3e8e55d14b8d689a3db4fa2d8ac3e9f

[^1_78]: https://www.semanticscholar.org/paper/104594edbe9c9ed75e3d7227cbc55a51ead677a6

[^1_79]: https://adasci.org/how-does-modular-rag-improve-upon-naive-rag/

[^1_80]: https://noeliabermudez.com/en/what-is-self-knowledge-and-how-to-develop-it/

[^1_81]: https://play.google.com/store/apps/details?hl=en_US\&id=de.inforapid.knowledgebasebuilder.android

[^1_82]: https://www.tandfonline.com/doi/full/10.1080/09658211.2024.2372373

[^1_83]: https://www.tandfonline.com/doi/full/10.1080/09658211.2023.2232568

[^1_84]: https://dl.acm.org/doi/10.1145/3631882.3631890

[^1_85]: https://www.tandfonline.com/doi/full/10.1080/09658211.2023.2277134

[^1_86]: https://academic.oup.com/book/31963/chapter/267697960

[^1_87]: https://academic.oup.com/book/35295/chapter/299912477

[^1_88]: https://dl.acm.org/doi/10.1145/3357526.3357569

[^1_89]: https://ieeexplore.ieee.org/document/8863521/

[^1_90]: https://firexcore.com/blog/memengine/

[^1_91]: https://ftp.cs.wisc.edu/sohi/papers/2000/miss-ex-decoupling.medea.pdf

[^1_92]: https://www.ece.iastate.edu/~zambreno/assets/pdf/TowAtt16A.pdf

[^1_93]: https://www.semanticscholar.org/paper/062249598fce6a3714a3134f90a624c33a9bb531

[^1_94]: https://ojs.observatoriolatinoamericano.com/ojs/index.php/olel/article/view/8251

[^1_95]: https://journals.sagepub.com/doi/10.1177/1548512919886163

[^1_96]: https://www.semanticscholar.org/paper/e3458c649154317307d5819c54604ae299a02867

[^1_97]: https://www.semanticscholar.org/paper/3afb242a210cee702d18e784d3f8a3864661767d

[^1_98]: https://www.mdpi.com/2504-446X/9/4/309

[^1_99]: https://ieeexplore.ieee.org/document/10322871/

[^1_100]: https://www.marktechpost.com/2025/01/21/what-are-haystack-agents-a-comprehensive-guide-to-tool-driven-nlp-with-code-implementation/

[^1_101]: https://haystack.deepset.ai/tutorials/45_creating_a_multi_agent_system

[^1_102]: https://www.youtube.com/watch?v=tKyvkU69Ers

[^1_103]: https://ieeexplore.ieee.org/document/10986609/

[^1_104]: https://aacrjournals.org/cancerres/article/85/8_Supplement_1/2296/760742/Abstract-2296-Ascertainment-of-uterine-cancer

[^1_105]: https://doi.apa.org/doi/10.1037/xhp0001268

[^1_106]: https://doi.apa.org/doi/10.1037/xge0001722

[^1_107]: http://pubs.rsna.org/doi/10.1148/ryai.240313

[^1_108]: https://ieeexplore.ieee.org/document/10700724/

[^1_109]: https://www.mdpi.com/2079-4991/15/9/651

[^1_110]: https://www.ssph-journal.org/articles/10.3389/phrs.2025.1607444/full

[^1_111]: https://dataaspirant.com/popular-vector-databases/

[^1_112]: https://github.com/sshibinthomass/RAG-FAISS-and-Chroma

[^1_113]: https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=10946287

[^1_114]: https://ieeexplore.ieee.org/xpl/mostRecentIssue.jsp?punumber=10978855

[^1_115]: https://www.semanticscholar.org/paper/361df412eb93838139ee90614e60f767247ca305

[^1_116]: https://blog.langchain.dev/interrupt-2025-recap/

[^1_117]: https://arxiv.org/abs/2504.08999

[^1_118]: https://www.semanticscholar.org/paper/d94110f998188446acd6c0217bccf5ecc46cb12a

[^1_119]: https://github.com/modelcontextprotocol

[^1_120]: https://www.semanticscholar.org/paper/06f2e16b9e19268d714b956af49649b2e8c79fc3

[^1_121]: https://www.semanticscholar.org/paper/fb7075a72792d1eab5dfb84bf83bdadadbc500ad

[^1_122]: https://www.semanticscholar.org/paper/acdff1ba5892587363d41a02dd810a99bc57ae9f

[^1_123]: https://www.semanticscholar.org/paper/2c90125442486884b1f3bf7a415fa4fdfc1a5a03

[^1_124]: http://link.springer.com/10.1007/3-540-36228-2_121

[^1_125]: https://aacrjournals.org/clincancerres/article/12/19/5777/192847/Phase-I-Study-of-Decitabine-Mediated-Gene

[^1_126]: http://www.palgraveconnect.com/doifinder/10.1057/9780230354456.0014

[^1_127]: https://journals.sagepub.com/doi/10.1007/BF03182038

[^1_128]: https://www.elastic.co/docs/extend/integrations/manifest-spec

[^1_129]: https://github.com/microsoft/learn-declarative-agent-vscode/blob/main/teamsapp.yml

[^1_130]: https://www.tandfonline.com/doi/full/10.1080/09544828.2017.1307949

[^1_131]: https://arxiv.org/abs/2504.08761

[^1_132]: http://www.tandfonline.com/doi/abs/10.1080/713755518

[^1_133]: https://dl.acm.org/doi/10.1145/3240302.3240311

[^1_134]: https://www.semanticscholar.org/paper/33f844d18a20b56dd9419afc5d18586b8646c25d

[^1_135]: https://ieeexplore.ieee.org/document/10857820/

[^1_136]: https://docs.haystack.deepset.ai/docs/agents

[^1_137]: https://doi.apa.org/doi/10.1037/dev0001913

[^1_138]: https://www.ndss-symposium.org/wp-content/uploads/2025-2287-paper.pdf

[^1_139]: https://www.turing.com/resources/vector-database-comparison

[^1_140]: https://lakefs.io/blog/12-vector-databases-2023/

[^1_141]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/d03fd8d0-9a27-4201-9f91-52c9599bdee4/fdc2718e.csv

[^1_142]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/d03fd8d0-9a27-4201-9f91-52c9599bdee4/e721cc99.json

[^1_143]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/dc9f1aae-f01f-4061-9a87-07d7336f3bcc/7e75bcaa.json

[^1_144]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/dc9f1aae-f01f-4061-9a87-07d7336f3bcc/c38f9dc1.json

[^1_145]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/57a0a2a6-1ba7-42bf-8d5b-fe5120a0c319/c8d9469a.csv

[^1_146]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/57a0a2a6-1ba7-42bf-8d5b-fe5120a0c319/b8a0aead.csv

[^1_147]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/57a0a2a6-1ba7-42bf-8d5b-fe5120a0c319/5707cacc.csv

[^1_148]: https://ppl-ai-code-interpreter-files.s3.amazonaws.com/web/direct-files/33a17c8e61ecb5f37fb9a1a3b0fa0fce/b6415b64-7924-4cc3-99f7-5e6ff26c5759/04554c9d.yaml

